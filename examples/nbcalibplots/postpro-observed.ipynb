{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Postpro-observed notebook\n",
    "This notebook post-processes observed data in a HEC-DSS file. Observed data must be post-processed before creating plots using the plotting notebook. Post-processing does the following:\n",
    "1. Read DSS data matching each station (identified by DSS B part). For each constituent (Flow, Stage, EC), for each station, all matching DSS paths will be identified.\n",
    "2. After reading data in the matching DSS paths, the data in the paths will be combined into a single DSS data set, with priority given to shorter time interval data. If there are 15MIN data, all of it will be used. Any gaps will be filled with 1HOUR data. Any remaining gaps will be filled with 1DAY data. The data will be writen to a new dss file with \"_calib_postpro\" appended to the end of the filename. Example: if the input DSS file is \"flow.dss\", the output DSS file will be \"flow_calib_postpro.dss\". The B parts in the input DSS file must match one of the names in the \"CDEC ID\" field in the location file. The B parts will be renamed in the output DSS file to the corresponding name in the \"DSM2 ID\" file.\n",
    "3. The output DSS file will contain the following:\n",
    "    a. The original data set\n",
    "    b. An amplitude data set\n",
    "    c. A Godin filtered data set\n",
    "    d. A high value data set (local maximum values)\n",
    "    e. A low value data set (local minimum values)\n",
    "\n",
    "Required input\n",
    "=============\n",
    "1. One or more location (.csv) files, containing information about the data to be processed. There should be 3 fields in this file: \"DSM2 ID\", \"CDEC ID\", and \"Station Name\". Headers for these fields must be included. The values in the \"CDEC ID\" column must match a DSS B parts in the DSS file. Here is an excerpt from an example location file:\n",
    "    DSM2 ID\tCDEC ID\tStation Name\n",
    "    RSAC101\tRVB\tSacramento River at Rio Vista\n",
    "    RSAC092\tEMM\tSacramento River at Emmaton \n",
    "    RSAC081\tCLL\tSacramento River at Collinsville \n",
    "2. One of more data (.dss) files, containing the data you need to process. The data in this file will only be processed if the location file contains a \"CDEC ID\" matching its B part.\n",
    "\n",
    "Usage\n",
    "======\n",
    "1. In the \"Setup for EC\", \"Setup for Flow\", and \"Setup for Stage\" cells, set the variables to correctly identify the data to be processed.\n",
    "2. Execute the entire notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-06T19:59:30.929719Z",
     "start_time": "2021-07-06T19:59:30.880853Z"
    }
   },
   "outputs": [],
   "source": [
    "import pydsm\n",
    "from pydsm import postpro"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dask related functions\n",
    "Dask uses parallel processing, which will significantly reduce runtime.\n",
    "However, messages printed to stdout will not be displayed in the notebook.  \n",
    "This includes messages indicating that plots will not be created for        \n",
    "certain locations due to missing DSS data. These messages will be displayed \n",
    "in the conda prompt window. \n",
    "The use of dask with network drives is not recommended--some processes may fail.                                       \n",
    "This notebook writes DSS files, which does not work in Windows when         \n",
    "using dask. It works well in Linux. use_dask is set to False by default.    \n",
    "If using Linux, setting use_dask to True will increase speed.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-06T19:59:30.935694Z",
     "start_time": "2021-07-06T19:59:30.931710Z"
    }
   },
   "outputs": [],
   "source": [
    "# for Windows, should be False\n",
    "use_dask = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create Dask Cluster\n",
    "Using 8 workers here, each with a limit of 4GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-06T19:59:30.950859Z",
     "start_time": "2021-07-06T19:59:30.937683Z"
    }
   },
   "outputs": [],
   "source": [
    "import dask\n",
    "from dask.distributed import Client, LocalCluster\n",
    "\n",
    "class DaskCluster:\n",
    "    def __init__(self):\n",
    "        self.client=None\n",
    "    def start_local_cluster(self):\n",
    "        cluster = LocalCluster(n_workers=8, threads_per_worker=1, memory_limit='6G') # threads_per_worker=1 needed if using numba :(\n",
    "        self.client = Client(cluster)\n",
    "    def stop_local_cluster(self):\n",
    "        self.client.shutdown()\n",
    "        self.client=None\n",
    "\n",
    "def run_all(processors):\n",
    "    tasks=[dask.delayed(postpro.run_processor)(processor,dask_key_name=f'{processor.study.name}::{processor.location.name}/{processor.vartype.name}') for processor in processors]\n",
    "    if use_dask:\n",
    "        dask.compute(tasks)\n",
    "    else:\n",
    "        dask.compute(tasks, scheduler='single-threaded')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Dask cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-06T19:59:38.507065Z",
     "start_time": "2021-07-06T19:59:30.952853Z"
    }
   },
   "outputs": [],
   "source": [
    "cluster = DaskCluster()\n",
    "cluster.start_local_cluster()\n",
    "cluster.client"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup for EC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-06T20:21:25.994538Z",
     "start_time": "2021-07-06T19:59:39.097485Z"
    }
   },
   "outputs": [],
   "source": [
    "dssfile='./observed_data/ec_merged.dss'\n",
    "locationfile='./location_info/calibration_ec_stations.csv'\n",
    "vartype='EC'\n",
    "units='mmhos/cm'\n",
    "study_name='Observed'\n",
    "observed=True\n",
    "processors=postpro.build_processors(dssfile, locationfile, vartype, units, study_name, observed)\n",
    "run_all(processors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup for FLOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-06T20:38:47.966311Z",
     "start_time": "2021-07-06T20:21:26.435929Z"
    }
   },
   "outputs": [],
   "source": [
    "dssfile='./observed_data/flow_merged.dss'\n",
    "locationfile='./location_info/calibration_flow_stations.csv'\n",
    "vartype='FLOW'\n",
    "units='cfs'\n",
    "study_name='Observed'\n",
    "observed=True\n",
    "processors=postpro.build_processors(dssfile, locationfile, vartype, units, study_name, observed)\n",
    "for processor in processors:\n",
    "    if processor.vartype.name == 'FLOW' and processor.location.name == 'VCU':\n",
    "        processor.do_scale(-1)\n",
    "run_all(processors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup for STAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-06T20:55:22.867949Z",
     "start_time": "2021-07-06T20:38:48.571257Z"
    }
   },
   "outputs": [],
   "source": [
    "dssfile='./observed_data/stage_merged.dss'\n",
    "locationfile='./location_info/calibration_stage_stations.csv'\n",
    "vartype='STAGE'\n",
    "units='feet'\n",
    "study_name='Observed'\n",
    "observed=True\n",
    "processors=postpro.build_processors(dssfile, locationfile, vartype, units, study_name, observed)\n",
    "run_all(processors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shut down the cluster. Make sure this always runs when done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-06T20:55:38.432122Z",
     "start_time": "2021-07-06T20:55:23.355567Z"
    }
   },
   "outputs": [],
   "source": [
    "cluster.stop_local_cluster()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dev_pydelmod]",
   "language": "python",
   "name": "conda-env-dev_pydelmod-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
