{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calibration Plot Generation Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T23:31:07.205852Z",
     "start_time": "2022-02-28T23:30:57.730598Z"
    }
   },
   "outputs": [],
   "source": [
    "import pydsm\n",
    "from pydsm import postpro\n",
    "\n",
    "import pydelmod\n",
    "from pydelmod import calibplot\n",
    "import panel as pn\n",
    "import pandas as pd\n",
    "import holoviews as hv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read Config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T23:31:07.237716Z",
     "start_time": "2022-02-28T23:31:07.208838Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "config_filename = 'postpro_config.json'\n",
    "f = open(config_filename)\n",
    "data = json.load(f)\n",
    "options_dict = data['options_dict']\n",
    "vartype_dict = data['vartype_dict']\n",
    "process_vartype_dict = data['process_vartype_dict']\n",
    "dask_options_dict = data['dask_options_dict']\n",
    "location_files_dict = data['location_files_dict']\n",
    "observed_files_dict = data['observed_files_dict']\n",
    "study_files_dict = data['study_files_dict']\n",
    "inst_plot_timewindow_dict = data['inst_plot_timewindow_dict']\n",
    "timewindow_dict = data['timewindow_dict']\n",
    "\n",
    "output_folder = options_dict['output_folder']\n",
    "timewindow = timewindow_dict[timewindow_dict['default_timewindow']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build and save plot for each location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T23:31:07.267592Z",
     "start_time": "2022-02-28T23:31:07.240702Z"
    },
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def export_svg(plot, fname):\n",
    "    ''' export holoview object to filename fname '''\n",
    "    from bokeh.io import export_svgs\n",
    "    p =  hv.render(plot, backend='bokeh')\n",
    "    p.output_backend = \"svg\"\n",
    "    export_svgs(p, filename=fname)\n",
    "\n",
    "def save_to_graphics_format(calib_plot_template,fname):\n",
    "#     hvobj=calib_plot_template[1][0]\n",
    "#     hvobj.object=hvobj.object.opts(toolbar=None) # remove the toolbar from the second row plot\n",
    "    calib_plot_template.save(fname)\n",
    "\n",
    "def build_and_save_plot(studies, location, vartype, timewindow, output_plot_dir, write_html=False, \n",
    "                        write_graphics=True, output_format='png'):\n",
    "    print(str(location))\n",
    "    flow_or_stage = (vartype.name == 'FLOW') or (vartype.name == 'STAGE')\n",
    "    if location=='RSAC128-RSAC123':\n",
    "        print('cross-delta flow')\n",
    "        flow_or_stage = False\n",
    "    flow_in_thousands = (vartype == 'FLOW')\n",
    "    \n",
    "    units = vartype.units\n",
    "    include_kde_plots = options_dict['include_kde_plots']\n",
    "    calib_plot_template, metrics_df = calibplot.build_calib_plot_template(studies, location, vartype, timewindow, \n",
    "                                                                          tidal_template=flow_or_stage, \n",
    "                                                                          flow_in_thousands=flow_in_thousands, units=units, \n",
    "                                                                          inst_plot_timewindow=inst_plot_timewindow,\n",
    "                                                                          include_kde_plots = include_kde_plots)\n",
    "    if calib_plot_template is None:\n",
    "        print('failed to create plots')\n",
    "    if metrics_df is None:\n",
    "        print('failed to create metrics')\n",
    "    if calib_plot_template is not None and metrics_df is not None:\n",
    "        if write_html: calib_plot_template.save(f'{output_plot_dir}{location.name}_{vartype.name}.html')\n",
    "        if write_graphics: \n",
    "            save_to_graphics_format(calib_plot_template,f'{output_plot_dir}{location}_{vartype.name}.png')\n",
    "    #         export_svg(calib_plot_template,f'{output_plot_dir}{location.name}_{vartype.name}.svg')\n",
    "    if metrics_df is not None:\n",
    "        location_list = []\n",
    "        for r in range(metrics_df.shape[0]):\n",
    "            location_list.append(location)\n",
    "        metrics_df['Location'] = location_list\n",
    "        # move Location column to beginning\n",
    "        cols = list(metrics_df)\n",
    "        cols.insert(0, cols.pop(cols.index('Location')))\n",
    "        metrics_df = metrics_df.loc[:, cols]\n",
    "\n",
    "        # files for individual studies\n",
    "        for study in study_files_dict:\n",
    "#             print(str(location))\n",
    "            metrics_df[metrics_df.index == study].to_csv(\n",
    "                output_plot_dir + '0_summary_statistics_' + study + '_' + vartype.name + '_' + location.name + '.csv')\n",
    "            # metrics_df[metrics_df.index==study].to_html(output_plot_dir+'0_summary_statistics_'+study+'_'+vartype.name+'_'+location.name+'.html')\n",
    "\n",
    "    return calib_plot_template, metrics_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# merge study statistics files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T23:31:07.283522Z",
     "start_time": "2022-02-28T23:31:07.269585Z"
    }
   },
   "outputs": [],
   "source": [
    "def merge_statistics_files(vartype):\n",
    "    import glob, os\n",
    "    print('merging statistics files')\n",
    "    output_dir = options_dict['output_folder']\n",
    "    files = glob.glob(output_dir + '0_summary_statistics_*'+vartype.name+'*.csv')\n",
    "    frames = []\n",
    "    for f in files:\n",
    "        frames.append(pd.read_csv(f))\n",
    "    result_df = pd.concat(frames)\n",
    "    result_df.sort_values(by=['Location', 'DSM2 Run'], inplace=True, ascending=True)\n",
    "    result_df.to_csv(output_dir + '1_summary_statistics_all_'+vartype.name+'.csv', index=False)\n",
    "    for f in files:\n",
    "        os.remove(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Start Dask Cluster\n",
    "Using 8 workers here, each with a limit of 4GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T23:31:08.000151Z",
     "start_time": "2022-02-28T23:31:07.285513Z"
    }
   },
   "outputs": [],
   "source": [
    "import dask\n",
    "from dask.distributed import Client, LocalCluster\n",
    "\n",
    "class DaskCluster:\n",
    "    def __init__(self):\n",
    "        self.client=None\n",
    "    def start_local_cluster(self):\n",
    "        cluster = LocalCluster(n_workers=8, threads_per_worker=1, memory_limit='4G') # threads_per_worker=1 needed if using numba :(\n",
    "        self.client = Client(cluster)\n",
    "    def stop_local_cluster(self):\n",
    "        self.client.shutdown()\n",
    "        self.client=None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create cluster if using dask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T23:31:08.015085Z",
     "start_time": "2022-02-28T23:31:08.003137Z"
    }
   },
   "outputs": [],
   "source": [
    "cluster = None\n",
    "c_link = None\n",
    "if dask_options_dict['use_dask']:\n",
    "    cluster = DaskCluster()\n",
    "    cluster.start_local_cluster()\n",
    "    c_link=cluster.client\n",
    "    print(c_link)\n",
    "c_link"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set options and run processes. If using dask, create delayed tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-02-28T23:31:39.357925Z",
     "start_time": "2022-02-28T23:31:08.017076Z"
    }
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    for var_name in vartype_dict:\n",
    "        vartype = postpro.VarType(var_name, vartype_dict[var_name])\n",
    "        print('vartype='+str(vartype))\n",
    "        if process_vartype_dict[vartype.name]:\n",
    "            # set a separate timewindow for instantaneous plots\n",
    "            inst_plot_timewindow = inst_plot_timewindow_dict[vartype.name]\n",
    "            ## Load locations from a .csv file, and create a list of postpro.Location objects\n",
    "            #The .csv file should have atleast 'Name','BPart' and 'Description' columns\n",
    "            locationfile=location_files_dict[vartype.name]\n",
    "            dfloc = postpro.load_location_file(locationfile)\n",
    "            locations=[postpro.Location(r['Name'],r['BPart'],r['Description']) for i,r in dfloc.iterrows()]\n",
    "            # create list of postpro.Study objects, with observed Study followed by model Study objects\n",
    "            obs_study=postpro.Study('Observed',observed_files_dict[vartype.name])\n",
    "            model_studies=[postpro.Study(name,study_files_dict[name]) for name in study_files_dict]\n",
    "            studies=[obs_study]+model_studies\n",
    "            # now run the processes\n",
    "            if dask_options_dict['use_dask']:\n",
    "                print('using dask')\n",
    "                tasks=[dask.delayed(build_and_save_plot)(studies, location, vartype, timewindow, output_folder,\n",
    "                                                 write_html=True,write_graphics=False) for location in locations]\n",
    "                dask.compute(tasks)\n",
    "            else:\n",
    "                print('not using dask')\n",
    "                for location in locations:\n",
    "                    build_and_save_plot(studies, location, vartype, timewindow, output_folder,\n",
    "                                                 write_html=True,write_graphics=False)\n",
    "            merge_statistics_files(vartype)\n",
    "finally:\n",
    "    if dask_options_dict['use_dask']:\n",
    "        cluster.stop_local_cluster()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dms_new]",
   "language": "python",
   "name": "conda-env-dms_new-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
